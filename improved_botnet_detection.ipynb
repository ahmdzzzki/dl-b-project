{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tugas Mata Kuliah Deep Learning\n",
    "\n",
    "### **Nama:** Ahmad Zaki  \n",
    "### **NIM:** 225150201111025  \n",
    "### **Dosen Pengampu:** Pak Rijal  \n",
    "\n",
    "---\n",
    "\n",
    "## **Judul Tugas: Deteksi Botnet Menggunakan Deep Learning**\n",
    "\n",
    "### **Deskripsi Singkat:**\n",
    "Pada tugas ini, dilakukan implementasi deep learning untuk mendeteksi aktivitas botnet menggunakan dataset CTU-13. Proses dimulai dengan analisis data, preprocessing, hingga pembuatan model deep learning. Model yang digunakan adalah Fully Connected Neural Network (FCNN) yang dilatih dengan data dari file `capture20110811.binetflow`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Tujuan Tugas:**\n",
    "1. Memahami proses pembuatan model deep learning dari awal hingga akhir.\n",
    "2. Mengimplementasikan teknik preprocessing seperti feature scaling dan data sampling.\n",
    "3. Melakukan eksperimen pada data jaringan untuk mendeteksi botnet menggunakan deep learning.\n",
    "\n",
    "---\n",
    "\n",
    "### **Tahapan Pengerjaan:**\n",
    "1. Data Understanding\n",
    "2. Exploratory Data Analysis (EDA)\n",
    "3. Preprocessing dan Feature Engineering\n",
    "4. Modeling dan Evaluasi\n",
    "5. Sampling dengan Teknik SMOTE\n",
    "\n",
    "---\n",
    "\n",
    "### **Tools yang Digunakan:**\n",
    "- Python (Libraries: TensorFlow, pandas, numpy, matplotlib, seaborn)\n",
    "- Jupyter Notebook\n",
    "- Dataset CTU-13\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Understanding dan Preliminary Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "from imblearn.combine import SMOTETomek\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../dl-b-project/2/capture20110811.binetflow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Overview:\n",
      "                    StartTime       Dur Proto       SrcAddr  Sport    Dir  \\\n",
      "0  2011/08/11 09:53:40.240135  9.016532   tcp  31.96.153.11  60257     ->   \n",
      "1  2011/08/11 09:55:01.054702  2.903761   tcp  83.228.37.92   2571     ->   \n",
      "2  2011/08/11 09:55:02.677188  3.032142   tcp  83.228.37.92   2574     ->   \n",
      "3  2011/08/11 09:55:04.307051  2.932428   tcp  83.228.37.92   2576     ->   \n",
      "4  2011/08/11 09:55:03.958463  6.017523   tcp  83.228.37.92   2571     ->   \n",
      "\n",
      "         DstAddr  Dport   State  sTos  dTos  TotPkts  TotBytes  SrcBytes  \\\n",
      "0  147.32.84.229    443  SRA_SA   0.0   0.0        7       508       208   \n",
      "1  147.32.84.229  13363   SR_SA   0.0   0.0        3       184       122   \n",
      "2  147.32.84.229    443   SR_SA   0.0   0.0        3       184       122   \n",
      "3  147.32.84.229     80   SR_SA   0.0   0.0        3       184       122   \n",
      "4  147.32.84.229  13363   SR_SA   0.0   0.0        3       184       122   \n",
      "\n",
      "                             Label  \n",
      "0  flow=Background-TCP-Established  \n",
      "1  flow=Background-TCP-Established  \n",
      "2  flow=Background-TCP-Established  \n",
      "3  flow=Background-TCP-Established  \n",
      "4  flow=Background-TCP-Established  \n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset Overview:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1808122 entries, 0 to 1808121\n",
      "Data columns (total 15 columns):\n",
      " #   Column     Dtype  \n",
      "---  ------     -----  \n",
      " 0   StartTime  object \n",
      " 1   Dur        float64\n",
      " 2   Proto      object \n",
      " 3   SrcAddr    object \n",
      " 4   Sport      object \n",
      " 5   Dir        object \n",
      " 6   DstAddr    object \n",
      " 7   Dport      object \n",
      " 8   State      object \n",
      " 9   sTos       float64\n",
      " 10  dTos       float64\n",
      " 11  TotPkts    int64  \n",
      " 12  TotBytes   int64  \n",
      " 13  SrcBytes   int64  \n",
      " 14  Label      object \n",
      "dtypes: float64(3), int64(3), object(9)\n",
      "memory usage: 206.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDataset Info:\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Descriptive Statistics:\n",
      "                Dur          sTos          dTos       TotPkts      TotBytes  \\\n",
      "count  1.808122e+06  1.803798e+06  1.538287e+06  1.808122e+06  1.808122e+06   \n",
      "mean   4.006726e+02  2.970399e-02  3.510398e-04  3.973805e+01  3.503811e+04   \n",
      "std    9.516550e+02  2.297207e+00  2.970989e-02  4.073724e+03  4.190502e+06   \n",
      "min    0.000000e+00  0.000000e+00  0.000000e+00  1.000000e+00  6.000000e+01   \n",
      "25%    3.140000e-04  0.000000e+00  0.000000e+00  2.000000e+00  2.140000e+02   \n",
      "50%    2.147000e-03  0.000000e+00  0.000000e+00  2.000000e+00  2.610000e+02   \n",
      "75%    8.996974e+00  0.000000e+00  0.000000e+00  5.000000e+00  5.870000e+02   \n",
      "max    3.600034e+03  1.920000e+02  3.000000e+00  4.077379e+06  4.376239e+09   \n",
      "\n",
      "           SrcBytes  \n",
      "count  1.808122e+06  \n",
      "mean   2.210684e+03  \n",
      "std    3.034949e+05  \n",
      "min    0.000000e+00  \n",
      "25%    7.900000e+01  \n",
      "50%    8.500000e+01  \n",
      "75%    3.100000e+02  \n",
      "max    2.485222e+08  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDescriptive Statistics:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique Labels in 'Label':\n",
      "Label\n",
      "flow=To-Background-UDP-CVUT-DNS-Server                                     660177\n",
      "flow=Background-UDP-Established                                            602264\n",
      "flow=Background-UDP-Attempt                                                201380\n",
      "flow=Background-TCP-Established                                            149962\n",
      "flow=Background-Established-cmpgw-CVUT                                      78133\n",
      "                                                                            ...  \n",
      "flow=From-Botnet-V43-TCP-Established-HTTP-Ad-60                                 1\n",
      "flow=From-Botnet-V43-TCP-HTTP-Not-Encrypted-Down-2                              1\n",
      "flow=From-Botnet-V43-TCP-Established-HTTP-Binary-Download-Custom-Port-5         1\n",
      "flow=From-Botnet-V43-TCP-Established-HTTP-Binary-Download-Custom-Port-7         1\n",
      "flow=From-Botnet-V43-TCP-Established-HTTP-Ad-23                                 1\n",
      "Name: count, Length: 132, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nUnique Labels in 'Label':\")\n",
    "print(df['Label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StartTime         0\n",
       "Dur               0\n",
       "Proto             0\n",
       "SrcAddr           0\n",
       "Sport          3993\n",
       "Dir               0\n",
       "DstAddr           0\n",
       "Dport          2973\n",
       "State             0\n",
       "sTos           4324\n",
       "dTos         269835\n",
       "TotPkts           0\n",
       "TotBytes          0\n",
       "SrcBytes          0\n",
       "Label             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    \"\"\"\n",
    "    Membersihkan dataset dari missing values, outliers, dan data yang tidak valid\n",
    "    \"\"\"\n",
    "    print(\"Jumlah data awal:\", len(df))\n",
    "    \n",
    "    # 1. Handling Missing Values\n",
    "    print(\"\\nMissing values sebelum cleaning:\")\n",
    "    print(df.isnull().sum())\n",
    "    \n",
    "    # Fill missing values\n",
    "    df['Sport'] = df['Sport'].fillna('unknown')\n",
    "    df['Dport'] = df['Dport'].fillna('unknown')\n",
    "    df['sTos'] = df['sTos'].fillna(df['sTos'].median())\n",
    "    df['dTos'] = df['dTos'].fillna(df['dTos'].median())\n",
    "    \n",
    "    # 2. Remove Invalid Values\n",
    "    # Remove rows where Dur is negative\n",
    "    df = df[df['Dur'] >= 0]\n",
    "    \n",
    "    # Remove rows where TotBytes is 0 but TotPkts is not 0\n",
    "    df = df[~((df['TotBytes'] == 0) & (df['TotPkts'] > 0))]\n",
    "    \n",
    "    # Remove rows where SrcBytes > TotBytes\n",
    "    df = df[df['SrcBytes'] <= df['TotBytes']]\n",
    "    \n",
    "    # 3. Handle Outliers\n",
    "    # Using IQR method for numerical columns\n",
    "    numeric_cols = ['Dur', 'TotPkts', 'TotBytes', 'SrcBytes']\n",
    "    \n",
    "    for col in numeric_cols:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 3 * IQR  # Using 3 instead of 1.5 to be less aggressive\n",
    "        upper_bound = Q3 + 3 * IQR\n",
    "        \n",
    "        # Cap the outliers instead of removing them\n",
    "        df[col] = df[col].clip(lower=lower_bound, upper=upper_bound)\n",
    "    \n",
    "    # 4. Data Validation\n",
    "    # Ensure all numeric columns are positive\n",
    "    for col in numeric_cols:\n",
    "        df[col] = df[col].abs()\n",
    "    \n",
    "    # 5. Convert Label ke format biner\n",
    "    df['Label'] = df['Label'].apply(lambda x: 1 if 'Botnet' in x else 0)\n",
    "    \n",
    "    # 6. Remove duplicates if any\n",
    "    df = df.drop_duplicates()\n",
    "    \n",
    "    print(\"\\nMissing values setelah cleaning:\")\n",
    "    print(df.isnull().sum())\n",
    "    print(\"\\nJumlah data setelah cleaning:\", len(df))\n",
    "    \n",
    "    # 7. Print class distribution\n",
    "    print(\"\\nDistribusi kelas setelah cleaning:\")\n",
    "    print(df['Label'].value_counts(normalize=True) * 100)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhanced_feature_engineering(df):\n",
    "    # Time-based features\n",
    "    df['StartTime'] = pd.to_datetime(df['StartTime'])\n",
    "    df['Hour'] = df['StartTime'].dt.hour\n",
    "    df['Day'] = df['StartTime'].dt.day\n",
    "    df['Month'] = df['StartTime'].dt.month\n",
    "    df['DayOfWeek'] = df['StartTime'].dt.dayofweek\n",
    "    df['IsWeekend'] = df['StartTime'].dt.dayofweek.isin([5, 6]).astype(int)\n",
    "    \n",
    "    # Traffic-based features\n",
    "    df['BytesPerPacket'] = df['TotBytes'] / df['TotPkts'].replace(0, 1)\n",
    "    df['BytesPerSecond'] = df['TotBytes'] / df['Dur'].replace(0, 1)\n",
    "    df['PacketsPerSecond'] = df['TotPkts'] / df['Dur'].replace(0, 1)\n",
    "    df['SrcBytesRatio'] = df['SrcBytes'] / df['TotBytes'].replace(0, 1)\n",
    "    \n",
    "    # Interaction features\n",
    "    df['BytePacketRatio'] = df['BytesPerPacket'] * df['PacketsPerSecond']\n",
    "    df['DurByteRatio'] = df['Dur'] * df['BytesPerSecond']\n",
    "    \n",
    "    # Protocol and State encoding using target encoding\n",
    "    for col in ['Proto', 'State', 'Dir']:\n",
    "        temp_dict = df.groupby(col)['Label'].mean()\n",
    "        df[f'{col}_encoded'] = df[col].map(temp_dict)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    # Select features for model\n",
    "    features = [\n",
    "        'Dur', 'Proto_encoded', 'State_encoded', 'Dir_encoded',\n",
    "        'sTos', 'dTos', 'TotPkts', 'TotBytes', 'SrcBytes',\n",
    "        'Hour', 'Day', 'Month', 'DayOfWeek', 'IsWeekend',\n",
    "        'BytesPerPacket', 'BytesPerSecond', 'PacketsPerSecond',\n",
    "        'SrcBytesRatio', 'BytePacketRatio', 'DurByteRatio'\n",
    "    ]\n",
    "    \n",
    "    # Feature selection using mutual information\n",
    "    selector = SelectKBest(score_func=mutual_info_classif, k=15)\n",
    "    X = selector.fit_transform(df[features], df['Label'])\n",
    "    selected_features = np.array(features)[selector.get_support()]\n",
    "    \n",
    "    # Robust scaling\n",
    "    scaler = RobustScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    return X_scaled, df['Label'], selected_features, scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_improved_model(input_dim):\n",
    "    model = models.Sequential([\n",
    "        layers.Dense(128, activation='relu', input_dim=input_dim,\n",
    "                    kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.4),\n",
    "        \n",
    "        layers.Dense(64, activation='relu',\n",
    "                    kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.3),\n",
    "        \n",
    "        layers.Dense(32, activation='relu',\n",
    "                    kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.2),\n",
    "        \n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    initial_learning_rate = 0.001\n",
    "    decay_steps = 1000\n",
    "    decay_rate = 0.9\n",
    "    learning_rate_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate, decay_steps, decay_rate\n",
    "    )\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate_schedule)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy',\n",
    "                tf.keras.metrics.Precision(),\n",
    "                tf.keras.metrics.Recall(),\n",
    "                tf.keras.metrics.AUC()]\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training with K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_kfold(X, y, n_splits=5):\n",
    "    kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    histories = []\n",
    "    models = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(X, y)):\n",
    "        print(f'\\nFold {fold + 1}/{n_splits}')\n",
    "        \n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "        \n",
    "        # Apply SMOTETomek\n",
    "        smote_tomek = SMOTETomek(random_state=42)\n",
    "        X_train_balanced, y_train_balanced = smote_tomek.fit_resample(X_train, y_train)\n",
    "        \n",
    "        # Calculate class weights\n",
    "        class_weights = dict(enumerate(np.bincount(y_train_balanced).max() / np.bincount(y_train_balanced)))\n",
    "        \n",
    "        # Create and train model\n",
    "        model = create_improved_model(X_train.shape[1])\n",
    "        \n",
    "        history = model.fit(\n",
    "            X_train_balanced, y_train_balanced,\n",
    "            epochs=20,\n",
    "            batch_size=256,\n",
    "            validation_data=(X_val, y_val),\n",
    "            class_weight=class_weights,\n",
    "            callbacks=[\n",
    "                tf.keras.callbacks.EarlyStopping(\n",
    "                    monitor='val_loss',\n",
    "                    patience=5,\n",
    "                    restore_best_weights=True\n",
    "                ),\n",
    "                tf.keras.callbacks.ReduceLROnPlateau(\n",
    "                    monitor='val_loss',\n",
    "                    factor=0.2,\n",
    "                    patience=3,\n",
    "                    min_lr=1e-6\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        histories.append(history.history)\n",
    "        models.append(model)\n",
    "    \n",
    "    return models, histories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah data awal: 1808122\n",
      "\n",
      "Missing values sebelum cleaning:\n",
      "StartTime         0\n",
      "Dur               0\n",
      "Proto             0\n",
      "SrcAddr           0\n",
      "Sport          3993\n",
      "Dir               0\n",
      "DstAddr           0\n",
      "Dport          2973\n",
      "State             0\n",
      "sTos           4324\n",
      "dTos         269835\n",
      "TotPkts           0\n",
      "TotBytes          0\n",
      "SrcBytes          0\n",
      "Label             0\n",
      "dtype: int64\n",
      "\n",
      "Missing values setelah cleaning:\n",
      "StartTime    0\n",
      "Dur          0\n",
      "Proto        0\n",
      "SrcAddr      0\n",
      "Sport        0\n",
      "Dir          0\n",
      "DstAddr      0\n",
      "Dport        0\n",
      "State        0\n",
      "sTos         0\n",
      "dTos         0\n",
      "TotPkts      0\n",
      "TotBytes     0\n",
      "SrcBytes     0\n",
      "Label        0\n",
      "dtype: int64\n",
      "\n",
      "Jumlah data setelah cleaning: 1808122\n",
      "\n",
      "Distribusi kelas setelah cleaning:\n",
      "Label\n",
      "0    98.841837\n",
      "1     1.158163\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Fold 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AHMAD ZAKI\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m11109/11109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 4ms/step - accuracy: 0.9278 - auc: 0.9807 - loss: 0.1905 - precision: 0.9281 - recall: 0.9275 - val_accuracy: 0.9558 - val_auc: 0.9914 - val_loss: 0.1356 - val_precision: 0.2007 - val_recall: 0.9448 - learning_rate: 3.1023e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m11109/11109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 4ms/step - accuracy: 0.9504 - auc: 0.9913 - loss: 0.1268 - precision: 0.9540 - recall: 0.9464 - val_accuracy: 0.9557 - val_auc: 0.9922 - val_loss: 0.1324 - val_precision: 0.2013 - val_recall: 0.9520 - learning_rate: 9.6241e-05\n",
      "Epoch 3/20\n",
      "\u001b[1m11109/11109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 4ms/step - accuracy: 0.9539 - auc: 0.9924 - loss: 0.1180 - precision: 0.9578 - recall: 0.9497 - val_accuracy: 0.9592 - val_auc: 0.9926 - val_loss: 0.1249 - val_precision: 0.2146 - val_recall: 0.9496 - learning_rate: 2.9857e-05\n",
      "Epoch 4/20\n",
      "\u001b[1m11109/11109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 4ms/step - accuracy: 0.9549 - auc: 0.9927 - loss: 0.1150 - precision: 0.9591 - recall: 0.9504 - val_accuracy: 0.9593 - val_auc: 0.9926 - val_loss: 0.1234 - val_precision: 0.2153 - val_recall: 0.9499 - learning_rate: 9.2623e-06\n",
      "Epoch 5/20\n",
      "\u001b[1m11109/11109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 4ms/step - accuracy: 0.9557 - auc: 0.9928 - loss: 0.1136 - precision: 0.9598 - recall: 0.9512 - val_accuracy: 0.9584 - val_auc: 0.9927 - val_loss: 0.1247 - val_precision: 0.2115 - val_recall: 0.9515 - learning_rate: 2.8734e-06\n",
      "Epoch 6/20\n",
      "\u001b[1m11109/11109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 4ms/step - accuracy: 0.9557 - auc: 0.9928 - loss: 0.1139 - precision: 0.9597 - recall: 0.9513 - val_accuracy: 0.9600 - val_auc: 0.9927 - val_loss: 0.1224 - val_precision: 0.2184 - val_recall: 0.9508 - learning_rate: 8.9141e-07\n",
      "Epoch 7/20\n",
      "\u001b[1m11109/11109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 4ms/step - accuracy: 0.9556 - auc: 0.9929 - loss: 0.1135 - precision: 0.9597 - recall: 0.9512 - val_accuracy: 0.9599 - val_auc: 0.9927 - val_loss: 0.1233 - val_precision: 0.2180 - val_recall: 0.9508 - learning_rate: 2.7654e-07\n",
      "Epoch 8/20\n",
      "\u001b[1m11109/11109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 4ms/step - accuracy: 0.9558 - auc: 0.9928 - loss: 0.1136 - precision: 0.9600 - recall: 0.9513 - val_accuracy: 0.9603 - val_auc: 0.9927 - val_loss: 0.1221 - val_precision: 0.2195 - val_recall: 0.9494 - learning_rate: 8.5791e-08\n",
      "Epoch 9/20\n",
      "\u001b[1m11109/11109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 4ms/step - accuracy: 0.9557 - auc: 0.9928 - loss: 0.1138 - precision: 0.9598 - recall: 0.9512 - val_accuracy: 0.9611 - val_auc: 0.9927 - val_loss: 0.1209 - val_precision: 0.2230 - val_recall: 0.9491 - learning_rate: 2.6615e-08\n",
      "Epoch 10/20\n",
      "\u001b[1m11109/11109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 4ms/step - accuracy: 0.9558 - auc: 0.9928 - loss: 0.1136 - precision: 0.9599 - recall: 0.9513 - val_accuracy: 0.9601 - val_auc: 0.9927 - val_loss: 0.1230 - val_precision: 0.2185 - val_recall: 0.9499 - learning_rate: 8.2566e-09\n",
      "Epoch 11/20\n",
      "\u001b[1m11109/11109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 4ms/step - accuracy: 0.9558 - auc: 0.9929 - loss: 0.1133 - precision: 0.9601 - recall: 0.9511 - val_accuracy: 0.9605 - val_auc: 0.9927 - val_loss: 0.1219 - val_precision: 0.2204 - val_recall: 0.9494 - learning_rate: 2.5614e-09\n",
      "Epoch 12/20\n",
      "\u001b[1m11109/11109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 4ms/step - accuracy: 0.9557 - auc: 0.9928 - loss: 0.1138 - precision: 0.9600 - recall: 0.9510 - val_accuracy: 0.9609 - val_auc: 0.9927 - val_loss: 0.1208 - val_precision: 0.2220 - val_recall: 0.9491 - learning_rate: 7.9462e-10\n",
      "Epoch 13/20\n",
      "\u001b[1m11109/11109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 4ms/step - accuracy: 0.9557 - auc: 0.9928 - loss: 0.1137 - precision: 0.9597 - recall: 0.9513 - val_accuracy: 0.9598 - val_auc: 0.9927 - val_loss: 0.1233 - val_precision: 0.2175 - val_recall: 0.9508 - learning_rate: 2.4651e-10\n",
      "Epoch 14/20\n",
      "\u001b[1m11109/11109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 4ms/step - accuracy: 0.9559 - auc: 0.9928 - loss: 0.1133 - precision: 0.9599 - recall: 0.9515 - val_accuracy: 0.9609 - val_auc: 0.9927 - val_loss: 0.1203 - val_precision: 0.2222 - val_recall: 0.9491 - learning_rate: 7.6475e-11\n",
      "Epoch 15/20\n",
      "\u001b[1m11109/11109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 4ms/step - accuracy: 0.9557 - auc: 0.9928 - loss: 0.1136 - precision: 0.9598 - recall: 0.9512 - val_accuracy: 0.9590 - val_auc: 0.9927 - val_loss: 0.1229 - val_precision: 0.2140 - val_recall: 0.9506 - learning_rate: 2.3725e-11\n",
      "Epoch 16/20\n",
      "\u001b[1m11109/11109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 4ms/step - accuracy: 0.9555 - auc: 0.9927 - loss: 0.1141 - precision: 0.9594 - recall: 0.9512 - val_accuracy: 0.9589 - val_auc: 0.9927 - val_loss: 0.1227 - val_precision: 0.2136 - val_recall: 0.9501 - learning_rate: 7.3600e-12\n",
      "Epoch 17/20\n",
      "\u001b[1m11109/11109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 4ms/step - accuracy: 0.9557 - auc: 0.9928 - loss: 0.1135 - precision: 0.9600 - recall: 0.9511 - val_accuracy: 0.9600 - val_auc: 0.9927 - val_loss: 0.1225 - val_precision: 0.2184 - val_recall: 0.9503 - learning_rate: 2.2833e-12\n",
      "Epoch 18/20\n",
      "\u001b[1m11109/11109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 4ms/step - accuracy: 0.9558 - auc: 0.9928 - loss: 0.1137 - precision: 0.9599 - recall: 0.9513 - val_accuracy: 0.9603 - val_auc: 0.9927 - val_loss: 0.1223 - val_precision: 0.2195 - val_recall: 0.9491 - learning_rate: 7.0833e-13\n",
      "Epoch 19/20\n",
      "\u001b[1m11109/11109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 4ms/step - accuracy: 0.9556 - auc: 0.9928 - loss: 0.1136 - precision: 0.9599 - recall: 0.9510 - val_accuracy: 0.9591 - val_auc: 0.9927 - val_loss: 0.1226 - val_precision: 0.2144 - val_recall: 0.9496 - learning_rate: 2.1974e-13\n",
      "\n",
      "Fold 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AHMAD ZAKI\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m11108/11108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 4ms/step - accuracy: 0.9290 - auc_1: 0.9810 - loss: 0.1878 - precision_1: 0.9285 - recall_1: 0.9298 - val_accuracy: 0.9545 - val_auc_1: 0.9901 - val_loss: 0.1426 - val_precision_1: 0.1954 - val_recall_1: 0.9382 - learning_rate: 3.1026e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m11108/11108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 4ms/step - accuracy: 0.9511 - auc_1: 0.9914 - loss: 0.1262 - precision_1: 0.9552 - recall_1: 0.9465 - val_accuracy: 0.9547 - val_auc_1: 0.9915 - val_loss: 0.1329 - val_precision_1: 0.1973 - val_recall_1: 0.9475 - learning_rate: 9.6261e-05\n",
      "Epoch 3/20\n",
      "\u001b[1m11108/11108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 4ms/step - accuracy: 0.9540 - auc_1: 0.9923 - loss: 0.1180 - precision_1: 0.9584 - recall_1: 0.9492 - val_accuracy: 0.9588 - val_auc_1: 0.9917 - val_loss: 0.1254 - val_precision_1: 0.2123 - val_recall_1: 0.9444 - learning_rate: 2.9866e-05\n",
      "Epoch 4/20\n",
      "\u001b[1m11108/11108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 4ms/step - accuracy: 0.9552 - auc_1: 0.9926 - loss: 0.1151 - precision_1: 0.9600 - recall_1: 0.9500 - val_accuracy: 0.9602 - val_auc_1: 0.9919 - val_loss: 0.1236 - val_precision_1: 0.2182 - val_recall_1: 0.9439 - learning_rate: 9.2662e-06\n",
      "Epoch 5/20\n",
      "\u001b[1m11108/11108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 4ms/step - accuracy: 0.9555 - auc_1: 0.9927 - loss: 0.1142 - precision_1: 0.9604 - recall_1: 0.9504 - val_accuracy: 0.9597 - val_auc_1: 0.9919 - val_loss: 0.1238 - val_precision_1: 0.2164 - val_recall_1: 0.9449 - learning_rate: 2.8749e-06\n",
      "Epoch 6/20\n",
      "\u001b[1m11108/11108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 4ms/step - accuracy: 0.9558 - auc_1: 0.9928 - loss: 0.1133 - precision_1: 0.9609 - recall_1: 0.9503 - val_accuracy: 0.9590 - val_auc_1: 0.9919 - val_loss: 0.1258 - val_precision_1: 0.2134 - val_recall_1: 0.9458 - learning_rate: 8.9198e-07\n",
      "Epoch 7/20\n",
      "\u001b[1m11108/11108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 4ms/step - accuracy: 0.9558 - auc_1: 0.9928 - loss: 0.1133 - precision_1: 0.9608 - recall_1: 0.9502 - val_accuracy: 0.9595 - val_auc_1: 0.9919 - val_loss: 0.1243 - val_precision_1: 0.2155 - val_recall_1: 0.9453 - learning_rate: 2.7675e-07\n",
      "Epoch 8/20\n",
      "\u001b[1m11108/11108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 4ms/step - accuracy: 0.9559 - auc_1: 0.9928 - loss: 0.1134 - precision_1: 0.9611 - recall_1: 0.9503 - val_accuracy: 0.9589 - val_auc_1: 0.9919 - val_loss: 0.1256 - val_precision_1: 0.2132 - val_recall_1: 0.9456 - learning_rate: 8.5863e-08\n",
      "Epoch 9/20\n",
      "\u001b[1m11108/11108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 4ms/step - accuracy: 0.9558 - auc_1: 0.9928 - loss: 0.1137 - precision_1: 0.9608 - recall_1: 0.9503 - val_accuracy: 0.9602 - val_auc_1: 0.9919 - val_loss: 0.1228 - val_precision_1: 0.2185 - val_recall_1: 0.9446 - learning_rate: 2.6640e-08\n",
      "Epoch 10/20\n",
      "\u001b[1m11108/11108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 4ms/step - accuracy: 0.9557 - auc_1: 0.9928 - loss: 0.1135 - precision_1: 0.9608 - recall_1: 0.9502 - val_accuracy: 0.9592 - val_auc_1: 0.9920 - val_loss: 0.1251 - val_precision_1: 0.2144 - val_recall_1: 0.9460 - learning_rate: 8.2653e-09\n",
      "Epoch 11/20\n",
      "\u001b[1m11108/11108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 4ms/step - accuracy: 0.9560 - auc_1: 0.9928 - loss: 0.1134 - precision_1: 0.9608 - recall_1: 0.9508 - val_accuracy: 0.9592 - val_auc_1: 0.9919 - val_loss: 0.1252 - val_precision_1: 0.2143 - val_recall_1: 0.9456 - learning_rate: 2.5644e-09\n",
      "Epoch 12/20\n",
      "\u001b[1m11108/11108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 5ms/step - accuracy: 0.9559 - auc_1: 0.9928 - loss: 0.1135 - precision_1: 0.9610 - recall_1: 0.9505 - val_accuracy: 0.9599 - val_auc_1: 0.9919 - val_loss: 0.1230 - val_precision_1: 0.2171 - val_recall_1: 0.9446 - learning_rate: 7.9562e-10\n",
      "Epoch 13/20\n",
      "\u001b[1m11108/11108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 4ms/step - accuracy: 0.9559 - auc_1: 0.9929 - loss: 0.1131 - precision_1: 0.9610 - recall_1: 0.9504 - val_accuracy: 0.9599 - val_auc_1: 0.9919 - val_loss: 0.1232 - val_precision_1: 0.2173 - val_recall_1: 0.9451 - learning_rate: 2.4685e-10\n",
      "Epoch 14/20\n",
      "\u001b[1m11108/11108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 4ms/step - accuracy: 0.9558 - auc_1: 0.9929 - loss: 0.1133 - precision_1: 0.9609 - recall_1: 0.9503 - val_accuracy: 0.9597 - val_auc_1: 0.9919 - val_loss: 0.1240 - val_precision_1: 0.2165 - val_recall_1: 0.9451 - learning_rate: 7.6588e-11\n",
      "\n",
      "Fold 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AHMAD ZAKI\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m11107/11107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 5ms/step - accuracy: 0.9274 - auc_2: 0.9809 - loss: 0.1899 - precision_2: 0.9259 - recall_2: 0.9295 - val_accuracy: 0.9519 - val_auc_2: 0.9910 - val_loss: 0.1376 - val_precision_2: 0.1882 - val_recall_2: 0.9530 - learning_rate: 3.1029e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m11107/11107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 5ms/step - accuracy: 0.9488 - auc_2: 0.9910 - loss: 0.1290 - precision_2: 0.9511 - recall_2: 0.9461 - val_accuracy: 0.9540 - val_auc_2: 0.9919 - val_loss: 0.1313 - val_precision_2: 0.1957 - val_recall_2: 0.9570 - learning_rate: 9.6281e-05\n",
      "Epoch 3/20\n",
      "\u001b[1m11107/11107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 5ms/step - accuracy: 0.9522 - auc_2: 0.9920 - loss: 0.1203 - precision_2: 0.9549 - recall_2: 0.9493 - val_accuracy: 0.9597 - val_auc_2: 0.9922 - val_loss: 0.1232 - val_precision_2: 0.2175 - val_recall_2: 0.9551 - learning_rate: 2.9875e-05\n",
      "Epoch 4/20\n",
      "\u001b[1m11107/11107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 4ms/step - accuracy: 0.9532 - auc_2: 0.9923 - loss: 0.1174 - precision_2: 0.9559 - recall_2: 0.9501 - val_accuracy: 0.9608 - val_auc_2: 0.9923 - val_loss: 0.1203 - val_precision_2: 0.2221 - val_recall_2: 0.9542 - learning_rate: 9.2701e-06\n",
      "Epoch 5/20\n",
      "\u001b[1m11107/11107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 4ms/step - accuracy: 0.9539 - auc_2: 0.9925 - loss: 0.1161 - precision_2: 0.9570 - recall_2: 0.9506 - val_accuracy: 0.9607 - val_auc_2: 0.9923 - val_loss: 0.1204 - val_precision_2: 0.2218 - val_recall_2: 0.9549 - learning_rate: 2.8765e-06\n",
      "Epoch 6/20\n",
      "\u001b[1m11107/11107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 4ms/step - accuracy: 0.9538 - auc_2: 0.9925 - loss: 0.1161 - precision_2: 0.9564 - recall_2: 0.9509 - val_accuracy: 0.9608 - val_auc_2: 0.9923 - val_loss: 0.1205 - val_precision_2: 0.2222 - val_recall_2: 0.9542 - learning_rate: 8.9254e-07\n",
      "Epoch 7/20\n",
      "\u001b[1m11107/11107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 4ms/step - accuracy: 0.9539 - auc_2: 0.9925 - loss: 0.1157 - precision_2: 0.9571 - recall_2: 0.9504 - val_accuracy: 0.9610 - val_auc_2: 0.9923 - val_loss: 0.1203 - val_precision_2: 0.2233 - val_recall_2: 0.9544 - learning_rate: 2.7695e-07\n",
      "Epoch 8/20\n",
      "\u001b[1m11107/11107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 4ms/step - accuracy: 0.9538 - auc_2: 0.9925 - loss: 0.1156 - precision_2: 0.9567 - recall_2: 0.9506 - val_accuracy: 0.9608 - val_auc_2: 0.9923 - val_loss: 0.1207 - val_precision_2: 0.2225 - val_recall_2: 0.9546 - learning_rate: 8.5935e-08\n",
      "Epoch 9/20\n",
      "\u001b[1m11107/11107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 4ms/step - accuracy: 0.9536 - auc_2: 0.9925 - loss: 0.1162 - precision_2: 0.9565 - recall_2: 0.9505 - val_accuracy: 0.9603 - val_auc_2: 0.9923 - val_loss: 0.1228 - val_precision_2: 0.2201 - val_recall_2: 0.9551 - learning_rate: 2.6665e-08\n",
      "Epoch 10/20\n",
      "\u001b[1m11107/11107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 4ms/step - accuracy: 0.9539 - auc_2: 0.9925 - loss: 0.1158 - precision_2: 0.9568 - recall_2: 0.9506 - val_accuracy: 0.9608 - val_auc_2: 0.9923 - val_loss: 0.1206 - val_precision_2: 0.2224 - val_recall_2: 0.9546 - learning_rate: 8.2740e-09\n",
      "Epoch 11/20\n",
      "\u001b[1m11107/11107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 4ms/step - accuracy: 0.9541 - auc_2: 0.9925 - loss: 0.1159 - precision_2: 0.9569 - recall_2: 0.9510 - val_accuracy: 0.9606 - val_auc_2: 0.9923 - val_loss: 0.1212 - val_precision_2: 0.2215 - val_recall_2: 0.9544 - learning_rate: 2.5674e-09\n",
      "Epoch 12/20\n",
      "\u001b[1m11107/11107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 4ms/step - accuracy: 0.9538 - auc_2: 0.9925 - loss: 0.1162 - precision_2: 0.9569 - recall_2: 0.9505 - val_accuracy: 0.9607 - val_auc_2: 0.9923 - val_loss: 0.1213 - val_precision_2: 0.2218 - val_recall_2: 0.9544 - learning_rate: 7.9663e-10\n",
      "\n",
      "Fold 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AHMAD ZAKI\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m11109/11109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 5ms/step - accuracy: 0.9279 - auc_3: 0.9814 - loss: 0.1885 - precision_3: 0.9255 - recall_3: 0.9313 - val_accuracy: 0.9552 - val_auc_3: 0.9919 - val_loss: 0.1375 - val_precision_3: 0.1997 - val_recall_3: 0.9534 - learning_rate: 3.1023e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m11109/11109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 5ms/step - accuracy: 0.9494 - auc_3: 0.9909 - loss: 0.1294 - precision_3: 0.9517 - recall_3: 0.9466 - val_accuracy: 0.9581 - val_auc_3: 0.9929 - val_loss: 0.1280 - val_precision_3: 0.2111 - val_recall_3: 0.9556 - learning_rate: 9.6241e-05\n",
      "Epoch 3/20\n",
      "\u001b[1m11109/11109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 4ms/step - accuracy: 0.9525 - auc_3: 0.9919 - loss: 0.1208 - precision_3: 0.9554 - recall_3: 0.9493 - val_accuracy: 0.9601 - val_auc_3: 0.9931 - val_loss: 0.1237 - val_precision_3: 0.2192 - val_recall_3: 0.9546 - learning_rate: 2.9857e-05\n",
      "Epoch 4/20\n",
      "\u001b[1m11109/11109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 4ms/step - accuracy: 0.9537 - auc_3: 0.9922 - loss: 0.1178 - precision_3: 0.9566 - recall_3: 0.9506 - val_accuracy: 0.9598 - val_auc_3: 0.9932 - val_loss: 0.1232 - val_precision_3: 0.2179 - val_recall_3: 0.9551 - learning_rate: 9.2623e-06\n",
      "Epoch 5/20\n",
      "\u001b[1m11109/11109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 4ms/step - accuracy: 0.9542 - auc_3: 0.9923 - loss: 0.1169 - precision_3: 0.9574 - recall_3: 0.9507 - val_accuracy: 0.9599 - val_auc_3: 0.9933 - val_loss: 0.1230 - val_precision_3: 0.2184 - val_recall_3: 0.9553 - learning_rate: 2.8734e-06\n",
      "Epoch 6/20\n",
      "\u001b[1m11109/11109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 5ms/step - accuracy: 0.9543 - auc_3: 0.9924 - loss: 0.1166 - precision_3: 0.9573 - recall_3: 0.9511 - val_accuracy: 0.9600 - val_auc_3: 0.9933 - val_loss: 0.1231 - val_precision_3: 0.2189 - val_recall_3: 0.9553 - learning_rate: 8.9141e-07\n",
      "Epoch 7/20\n",
      "\u001b[1m11109/11109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 4ms/step - accuracy: 0.9545 - auc_3: 0.9924 - loss: 0.1162 - precision_3: 0.9574 - recall_3: 0.9514 - val_accuracy: 0.9614 - val_auc_3: 0.9933 - val_loss: 0.1199 - val_precision_3: 0.2253 - val_recall_3: 0.9549 - learning_rate: 2.7654e-07\n",
      "Epoch 8/20\n",
      "\u001b[1m11109/11109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 4ms/step - accuracy: 0.9544 - auc_3: 0.9924 - loss: 0.1165 - precision_3: 0.9574 - recall_3: 0.9510 - val_accuracy: 0.9601 - val_auc_3: 0.9933 - val_loss: 0.1229 - val_precision_3: 0.2195 - val_recall_3: 0.9553 - learning_rate: 8.5791e-08\n",
      "Epoch 9/20\n",
      "\u001b[1m11109/11109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 5ms/step - accuracy: 0.9544 - auc_3: 0.9925 - loss: 0.1162 - precision_3: 0.9576 - recall_3: 0.9511 - val_accuracy: 0.9602 - val_auc_3: 0.9933 - val_loss: 0.1227 - val_precision_3: 0.2200 - val_recall_3: 0.9553 - learning_rate: 2.6615e-08\n",
      "Epoch 10/20\n",
      "\u001b[1m11109/11109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 5ms/step - accuracy: 0.9544 - auc_3: 0.9924 - loss: 0.1163 - precision_3: 0.9573 - recall_3: 0.9513 - val_accuracy: 0.9606 - val_auc_3: 0.9933 - val_loss: 0.1222 - val_precision_3: 0.2213 - val_recall_3: 0.9551 - learning_rate: 8.2566e-09\n",
      "Epoch 11/20\n",
      "\u001b[1m11109/11109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 5ms/step - accuracy: 0.9543 - auc_3: 0.9924 - loss: 0.1162 - precision_3: 0.9572 - recall_3: 0.9512 - val_accuracy: 0.9599 - val_auc_3: 0.9933 - val_loss: 0.1239 - val_precision_3: 0.2184 - val_recall_3: 0.9553 - learning_rate: 2.5614e-09\n",
      "Epoch 12/20\n",
      "\u001b[1m11109/11109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 5ms/step - accuracy: 0.9545 - auc_3: 0.9924 - loss: 0.1164 - precision_3: 0.9574 - recall_3: 0.9514 - val_accuracy: 0.9605 - val_auc_3: 0.9933 - val_loss: 0.1223 - val_precision_3: 0.2210 - val_recall_3: 0.9551 - learning_rate: 7.9462e-10\n",
      "\n",
      "Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AHMAD ZAKI\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m11109/11109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 4ms/step - accuracy: 0.9274 - auc_4: 0.9802 - loss: 0.1927 - precision_4: 0.9291 - recall_4: 0.9256 - val_accuracy: 0.9565 - val_auc_4: 0.9913 - val_loss: 0.1266 - val_precision_4: 0.2037 - val_recall_4: 0.9489 - learning_rate: 3.1023e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m11109/11109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 4ms/step - accuracy: 0.9501 - auc_4: 0.9912 - loss: 0.1279 - precision_4: 0.9541 - recall_4: 0.9456 - val_accuracy: 0.9581 - val_auc_4: 0.9923 - val_loss: 0.1241 - val_precision_4: 0.2105 - val_recall_4: 0.9518 - learning_rate: 9.6241e-05\n",
      "Epoch 3/20\n",
      "\u001b[1m11109/11109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 4ms/step - accuracy: 0.9535 - auc_4: 0.9922 - loss: 0.1192 - precision_4: 0.9581 - recall_4: 0.9485 - val_accuracy: 0.9611 - val_auc_4: 0.9927 - val_loss: 0.1194 - val_precision_4: 0.2235 - val_recall_4: 0.9534 - learning_rate: 2.9857e-05\n",
      "Epoch 4/20\n",
      "\u001b[1m11109/11109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 4ms/step - accuracy: 0.9551 - auc_4: 0.9926 - loss: 0.1158 - precision_4: 0.9596 - recall_4: 0.9502 - val_accuracy: 0.9647 - val_auc_4: 0.9928 - val_loss: 0.1138 - val_precision_4: 0.2409 - val_recall_4: 0.9520 - learning_rate: 9.2623e-06\n",
      "Epoch 5/20\n",
      "\u001b[1m11109/11109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 5ms/step - accuracy: 0.9553 - auc_4: 0.9927 - loss: 0.1152 - precision_4: 0.9600 - recall_4: 0.9501 - val_accuracy: 0.9650 - val_auc_4: 0.9929 - val_loss: 0.1146 - val_precision_4: 0.2423 - val_recall_4: 0.9518 - learning_rate: 2.8734e-06\n",
      "Epoch 6/20\n",
      "\u001b[1m11109/11109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 4ms/step - accuracy: 0.9553 - auc_4: 0.9926 - loss: 0.1151 - precision_4: 0.9599 - recall_4: 0.9504 - val_accuracy: 0.9639 - val_auc_4: 0.9929 - val_loss: 0.1163 - val_precision_4: 0.2367 - val_recall_4: 0.9522 - learning_rate: 8.9141e-07\n",
      "Epoch 7/20\n",
      "\u001b[1m11109/11109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 4ms/step - accuracy: 0.9556 - auc_4: 0.9927 - loss: 0.1147 - precision_4: 0.9604 - recall_4: 0.9503 - val_accuracy: 0.9643 - val_auc_4: 0.9929 - val_loss: 0.1144 - val_precision_4: 0.2388 - val_recall_4: 0.9520 - learning_rate: 2.7654e-07\n",
      "Epoch 8/20\n",
      "\u001b[1m11109/11109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 4ms/step - accuracy: 0.9558 - auc_4: 0.9927 - loss: 0.1145 - precision_4: 0.9603 - recall_4: 0.9508 - val_accuracy: 0.9646 - val_auc_4: 0.9929 - val_loss: 0.1158 - val_precision_4: 0.2404 - val_recall_4: 0.9522 - learning_rate: 8.5791e-08\n",
      "Epoch 9/20\n",
      "\u001b[1m11109/11109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 4ms/step - accuracy: 0.9557 - auc_4: 0.9927 - loss: 0.1144 - precision_4: 0.9605 - recall_4: 0.9506 - val_accuracy: 0.9641 - val_auc_4: 0.9929 - val_loss: 0.1153 - val_precision_4: 0.2377 - val_recall_4: 0.9522 - learning_rate: 2.6615e-08\n",
      "\u001b[1m56504/56504\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 1ms/step\n",
      "\n",
      "Final Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98   1787181\n",
      "           1       0.24      0.95      0.38     20941\n",
      "\n",
      "    accuracy                           0.96   1808122\n",
      "   macro avg       0.62      0.96      0.68   1808122\n",
      "weighted avg       0.99      0.96      0.97   1808122\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (5,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 66\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m best_model, scaler, selected_features\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m     model, scaler, selected_features \u001b[38;5;241m=\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[23], line 38\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Plot average training history\u001b[39;00m\n\u001b[0;32m     37\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m---> 38\u001b[0m avg_history \u001b[38;5;241m=\u001b[39m \u001b[43m{\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mh\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhistories\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m              \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhistories\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m     41\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     42\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(avg_history[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining Loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[23], line 38\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Plot average training history\u001b[39;00m\n\u001b[0;32m     37\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m---> 38\u001b[0m avg_history \u001b[38;5;241m=\u001b[39m {metric: \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mh\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhistories\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m               \u001b[38;5;28;01mfor\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m histories[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mkeys()}\n\u001b[0;32m     41\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     42\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(avg_history[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining Loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\AHMAD ZAKI\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504\u001b[0m, in \u001b[0;36mmean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m   3501\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3502\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m mean(axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 3504\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_methods\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mean\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3505\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\AHMAD ZAKI\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\_methods.py:102\u001b[0m, in \u001b[0;36m_mean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_mean\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 102\u001b[0m     arr \u001b[38;5;241m=\u001b[39m asanyarray(a)\n\u001b[0;32m    104\u001b[0m     is_float16_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    106\u001b[0m     rcount \u001b[38;5;241m=\u001b[39m _count_reduce_items(arr, axis, keepdims\u001b[38;5;241m=\u001b[39mkeepdims, where\u001b[38;5;241m=\u001b[39mwhere)\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (5,) + inhomogeneous part."
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def main():\n",
    "    # Load data\n",
    "    df = pd.read_csv('../dl-b-project/2/capture20110811.binetflow')\n",
    "    \n",
    "    # Clean data\n",
    "    df = clean_data(df)    \n",
    "    \n",
    "    # Enhanced feature engineering\n",
    "    df = enhanced_feature_engineering(df)\n",
    "    \n",
    "    # Improved preprocessing\n",
    "    X, y, selected_features, scaler = preprocess_data(df)\n",
    "    \n",
    "    # Train with k-fold cross validation\n",
    "    models, histories = train_with_kfold(X, y)\n",
    "    \n",
    "    # Select best model based on validation metrics\n",
    "    best_model_idx = np.argmax([h['val_accuracy'][-1] for h in histories])\n",
    "    best_model = models[best_model_idx]\n",
    "    \n",
    "    # Final predictions using best model\n",
    "    y_pred = (best_model.predict(X) > 0.5).astype(int)\n",
    "    \n",
    "    # Print evaluation metrics\n",
    "    print(\"\\nFinal Classification Report:\")\n",
    "    print(classification_report(y, y_pred))\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(confusion_matrix(y, y_pred), annot=True, fmt='d')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot average training history\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    avg_history = {metric: np.mean([h[metric] for h in histories], axis=0)\n",
    "                  for metric in histories[0].keys()}\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(avg_history['loss'], label='Training Loss')\n",
    "    plt.plot(avg_history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Average Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(avg_history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(avg_history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Average Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # Save best model and preprocessing objects\n",
    "    best_model.save('best_botnet_detection_model.h5')\n",
    "    np.save('selected_features.npy', selected_features)\n",
    "    np.save('scaler.npy', scaler.get_params())\n",
    "    \n",
    "    return best_model, scaler, selected_features\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model, scaler, selected_features = main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
